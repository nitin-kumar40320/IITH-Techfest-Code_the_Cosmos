{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is new project for me where i am given a data of a set of inputs and output corresponding to each input and also the formula which can be used to find the value of the output from the input with some error.\n",
    "Now my task is to find the value of the three constants which are used in the formula that gives the output from the input."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing the necessary libraries which are needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now we import the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Redshift</th>\n",
       "      <th>Hubble parameter(km/s/Mpc)</th>\n",
       "      <th>Error in Hubble Parameter(km/s/Mpc)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.070</td>\n",
       "      <td>69.0</td>\n",
       "      <td>19.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.100</td>\n",
       "      <td>69.0</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.120</td>\n",
       "      <td>68.6</td>\n",
       "      <td>26.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.170</td>\n",
       "      <td>83.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.179</td>\n",
       "      <td>75.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Redshift  Hubble parameter(km/s/Mpc)  Error in Hubble Parameter(km/s/Mpc)\n",
       "0     0.070                        69.0                                 19.6\n",
       "1     0.100                        69.0                                 12.0\n",
       "2     0.120                        68.6                                 26.2\n",
       "3     0.170                        83.0                                  8.0\n",
       "4     0.179                        75.0                                  4.0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df= pd.read_csv('dataset.csv')\n",
    "df.head() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now we convert the pandas dataframe which contain the data into numpy arrays which are fairly easy to work with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.07  0.1   0.12  0.17  0.179 0.199 0.2   0.27  0.28  0.35  0.352 0.4\n",
      " 0.44  0.48  0.593 0.6   0.68  0.73  0.781 0.875 0.88  0.9   1.037 1.3\n",
      " 1.43  1.53  1.75  2.3  ] [ 69.   69.   68.6  83.   75.   75.   72.9  77.   88.8  76.3  83.   95.\n",
      "  82.6  97.  104.   87.9  92.   97.3 105.  125.   90.  117.  154.  168.\n",
      " 177.  140.  202.  224. ] [19.6 12.  26.2  8.   4.   5.  29.6 14.  36.6  5.6 14.  17.   7.8 62.\n",
      " 13.   6.1  8.   7.  12.  17.  40.  23.  20.  17.  18.  14.  40.   8. ]\n"
     ]
    }
   ],
   "source": [
    "xd=np.array(df['Redshift'])\n",
    "yd=np.array(df['Hubble parameter(km/s/Mpc)'])\n",
    "delyd=np.array(df['Error in Hubble Parameter(km/s/Mpc)'])\n",
    "print(xd,yd,delyd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have to make the necessary changes in the dataset which are mentioned in the presentation. So we convert the single feature input into a 2D array (feature1= (1+x)**3 and feature2= (1+x)**2) and also change the output as per the formula. We will also separate the error in the output from its main value and calculate the errors saparately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.225043    1.331       1.404928    1.601613    1.63885834  1.7236836\n",
      "   1.728       2.048383    2.097152    2.460375    2.47132621  2.744\n",
      "   2.985984    3.241792    4.04247486  4.096       4.741632    5.177717\n",
      "   5.64926254  6.59179688  6.644672    6.859       8.45226465 12.167\n",
      "  14.348907   16.194277   20.796875   35.937     ]\n",
      " [ 1.1449      1.21        1.2544      1.3689      1.390041    1.437601\n",
      "   1.44        1.6129      1.6384      1.8225      1.827904    1.96\n",
      "   2.0736      2.1904      2.537649    2.56        2.8224      2.9929\n",
      "   3.171961    3.515625    3.5344      3.61        4.149369    5.29\n",
      "   5.9049      6.4009      7.5625     10.89      ]] [0.89243512 0.89243512 0.88211804 1.29132231 1.05438932 1.05438932\n",
      " 0.99617016 1.1113732  1.47810199 1.09125827 1.29132231 1.69170908\n",
      " 1.27890583 1.76368873 2.02742664 1.4482923  1.58655132 1.77461501\n",
      " 2.06660306 2.92885922 1.51832062 2.56596185 4.44549281 5.29050385\n",
      " 5.87252675 3.673961   7.64858698 9.40534017] [0.53242098 0.33582658 0.69892501 0.28570329 0.14249461 0.17061166\n",
      " 0.83732971 0.43578489 1.26052814 0.19126106 0.4724005  0.6536295\n",
      " 0.27795679 2.30483792 0.5645928  0.24225821 0.32110306 0.30587697\n",
      " 0.5312182  0.88005643 1.39285637 1.081912   1.28127019 1.22135778\n",
      " 1.36164737 0.8394176  3.24695635 0.93965102]\n"
     ]
    }
   ],
   "source": [
    "x1=(1+xd)**3\n",
    "x2=(1+xd)**2\n",
    "x=np.vstack((x1,x2))\n",
    "# print(x)\n",
    "y=yd/73.04\n",
    "y=y**2\n",
    "# print(y)\n",
    "dely=delyd/yd\n",
    "dely+=0.0142387732749179\n",
    "dely*=2\n",
    "dely*=y\n",
    "print(x,y,dely)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "here we will not be doing any preprocessing as missing values, Nan, etc values are not present in the dataset and scaling will change the parameters from their original values which is not desirable in this case"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we shall use the Bayesian Ridge Regression model as the size of the dataset is small and also a real world dataset requiring greater precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import BayesianRidge\n",
    "model1=BayesianRidge()\n",
    "model2d=BayesianRidge()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we fit the model separately into the main values and the error term of the output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>BayesianRidge()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">BayesianRidge</label><div class=\"sk-toggleable__content\"><pre>BayesianRidge()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "BayesianRidge()"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.fit(x.T,y)\n",
    "model2d.fit(x.T,dely)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "here is the final answer for the main values of the parameters/constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.1646535  0.35964872] 0.2827349977938409\n"
     ]
    }
   ],
   "source": [
    "print(model1.coef_,model1.intercept_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "here is the final answer for the error values of the parameters/constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.03131676 0.01680515] 0.5604636445724958\n"
     ]
    }
   ],
   "source": [
    "print(model2d.coef_,model2d.intercept_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we try to test the constants for their values. Although separate training and testing samples should have been divided but due to small data, we will use the same data for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred1=model1.predict(x.T)\n",
    "pred2=model2d.predict(x.T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now we calculate the mean error in the output of the testing phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.43539831225997006\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "error1=mean_absolute_error(y,pred1)\n",
    "print(error1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4348458268086364\n"
     ]
    }
   ],
   "source": [
    "error2=mean_absolute_error(dely,pred2)\n",
    "print(error2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the mean errors are very small in comparison to the values of H and H0 and z, hence we can conclude that the values of the constants are highly precise"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
